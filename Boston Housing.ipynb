{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston housing price regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import modules \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from keras\n",
    "First step is to import boston housing data from kears.\n",
    "<br>The format is in array.\n",
    "<br>Training set and test set are separated based on seed(optional).\n",
    "<br>Input housing features and output housing prices are also separated.\n",
    "<br>Further information about the usage, please visit https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boston housing data from keras\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.boston_housing.load_data(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize input features\n",
    "Because the input features are in different scales, it is necessary to normalize the input features so that they share the same scales\n",
    "<br>sklearn.preprocessing.StandardScaler is used to normalize\n",
    "<br>DO NOT mix with sklearn.preprocessing.normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement StandardScaler to normalize features\n",
    "scaler = StandardScaler()\n",
    "# use fit_transform to obtain mean and variance for x_train (fit) and then normalize x_train (transform)\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "# use transform to normalize x_test \n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate validation set from original training set \n",
    "Use sklearn.model_selection.train_test_split to separate \n",
    "<br>Assign test_size or train_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate validation set from original training set\n",
    "# use train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train,y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build neural network\n",
    "Use a function to build this neural network with three hidden layers\n",
    "<br>This function use the numbers of neurons in each hidden layer as parameter (in total three input parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build neural network\n",
    "\n",
    "def boston_model(n_first,n_second,n_third):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # input layer\n",
    "    model.add(Dense(n_first,activation='relu',input_dim=x_train.shape[1])) \n",
    "    # input_shape can also be used to input the shape for input data \n",
    "    # model.add(Dense(n_first,activation='relu',input_shape = (x_train.shape[1],)))\n",
    "    \n",
    "    # hidden layers\n",
    "        # second layer\n",
    "    model.add(Dense(n_second,activation='relu')) # no need to specify input_dim in hidden layers\n",
    "        # third layer\n",
    "    model.add(Dense(n_third, activation='relu'))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(1)) # Since default activation function is linear, no need to define\n",
    "    # compilation\n",
    "    model.compile(optimizer='adam',loss='mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter selection\n",
    "Use dataframe to store the mae for validation under different combinations of neurons \n",
    "<br>This dataframe will then be used to find the best case and then use this combination to predict the outcome for test set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First is to create a dataframe to store result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=['first_hidden','second_hidden','third_hidden','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 4 columns):\n",
      "first_hidden     0 non-null object\n",
      "second_hidden    0 non-null object\n",
      "third_hidden     0 non-null object\n",
      "mae              0 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second is to train the model and get the mae from validation set \n",
    "<br>Parameters to be tested for each layer: \n",
    "<br>First layer: 20,30\n",
    "<br>Second layer: 12,18\n",
    "<br>Third layer: 3,10\n",
    "<br>In total 8 combinations\n",
    "<br><br>For each combination, epochs =30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yuasto\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Yuasto\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 22.4275 - val_loss: 22.3164\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 0s 49us/step - loss: 22.2484 - val_loss: 22.1432\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 22.0495 - val_loss: 21.9388\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 21.8150 - val_loss: 21.6918\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 21.5293 - val_loss: 21.3624\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 21.1457 - val_loss: 20.9328\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 20.6452 - val_loss: 20.3649\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 19.9935 - val_loss: 19.6423\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 19.1767 - val_loss: 18.7187\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 18.1280 - val_loss: 17.5482\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 16.8707 - val_loss: 16.1107\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 0s 102us/step - loss: 15.3345 - val_loss: 14.3300\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 0s 105us/step - loss: 13.5491 - val_loss: 12.4186\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 0s 105us/step - loss: 11.6435 - val_loss: 10.5981\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 9.9147 - val_loss: 9.0574\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 8.6377 - val_loss: 8.1554\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 0s 105us/step - loss: 7.9054 - val_loss: 7.4852\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 7.3175 - val_loss: 6.9713\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 6.8326 - val_loss: 6.5250\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 0s 96us/step - loss: 6.4110 - val_loss: 6.0807\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 6.0123 - val_loss: 5.6889\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 0s 96us/step - loss: 5.6806 - val_loss: 5.3396\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 5.3939 - val_loss: 5.0433\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 5.1297 - val_loss: 4.7351\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 4.8524 - val_loss: 4.5001\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 4.6381 - val_loss: 4.2885\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 4.4421 - val_loss: 4.0880\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 4.2962 - val_loss: 3.9238\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 0s 53us/step - loss: 4.1248 - val_loss: 3.7971\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.9731 - val_loss: 3.6499\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 3.8341 - val_loss: 3.5372\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.6880 - val_loss: 3.4393\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.5976 - val_loss: 3.3862\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 0s 105us/step - loss: 3.5195 - val_loss: 3.2995\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 3.4417 - val_loss: 3.2262\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 0s 96us/step - loss: 3.3764 - val_loss: 3.1787\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.3024 - val_loss: 3.1254\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.2568 - val_loss: 3.0625\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.1992 - val_loss: 2.9879\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 3.1491 - val_loss: 2.9108\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 3.1155 - val_loss: 2.9028\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 0s 99us/step - loss: 3.0554 - val_loss: 2.8368\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.0191 - val_loss: 2.8234\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.9994 - val_loss: 2.7702\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.9418 - val_loss: 2.7147\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 2.9116 - val_loss: 2.7148\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.8829 - val_loss: 2.6307\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.8612 - val_loss: 2.6234\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 2.8222 - val_loss: 2.6191\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 0s 99us/step - loss: 2.8072 - val_loss: 2.5722\n",
      "81/81 [==============================] - 0s 74us/step\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 23.0085 - val_loss: 22.7538\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 0s 97us/step - loss: 22.7384 - val_loss: 22.4936\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 22.4552 - val_loss: 22.2232\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 22.1460 - val_loss: 21.9105\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 21.7863 - val_loss: 21.5262\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 21.3373 - val_loss: 21.0235\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 20.7381 - val_loss: 20.3363\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 19.9229 - val_loss: 19.4061\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 18.8364 - val_loss: 18.1529\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 17.3884 - val_loss: 16.4761\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 15.5673 - val_loss: 14.3819\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 0s 49us/step - loss: 13.3452 - val_loss: 11.9818\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 10.9280 - val_loss: 9.7959\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 8.8246 - val_loss: 8.0882\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 7.6547 - val_loss: 7.3737\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 7.2296 - val_loss: 6.7903\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 6.7147 - val_loss: 6.2715\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 0s 49us/step - loss: 6.1847 - val_loss: 5.8021\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 5.7124 - val_loss: 5.3531\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 5.2514 - val_loss: 4.9072\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 4.8550 - val_loss: 4.5879\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 4.5121 - val_loss: 4.3612\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 4.2637 - val_loss: 4.1595\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 68us/step - loss: 4.0945 - val_loss: 4.0517\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.9664 - val_loss: 3.9050\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 3.8615 - val_loss: 3.7254\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.7585 - val_loss: 3.6147\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.6564 - val_loss: 3.5047\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.5821 - val_loss: 3.4231\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.5018 - val_loss: 3.3829\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.4464 - val_loss: 3.3339\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.3892 - val_loss: 3.2713\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 0s 49us/step - loss: 3.3360 - val_loss: 3.2323\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.2807 - val_loss: 3.1419\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.2348 - val_loss: 3.0777\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 3.1867 - val_loss: 3.0280\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.1398 - val_loss: 2.9566\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.1133 - val_loss: 2.8905\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.0599 - val_loss: 2.8562\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.0108 - val_loss: 2.7975\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.9604 - val_loss: 2.7067\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 2.9240 - val_loss: 2.6318\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.8679 - val_loss: 2.6029\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.8374 - val_loss: 2.5348\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.8189 - val_loss: 2.5116\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 2.7703 - val_loss: 2.4976\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.7382 - val_loss: 2.4503\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 2.6868 - val_loss: 2.4067\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.6839 - val_loss: 2.3541\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 2.6488 - val_loss: 2.3498\n",
      "81/81 [==============================] - 0s 62us/step\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 22.4814 - val_loss: 22.3870\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 22.3916 - val_loss: 22.2836\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 22.2759 - val_loss: 22.1511\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 22.1248 - val_loss: 21.9836\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 21.9286 - val_loss: 21.7679\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 21.6745 - val_loss: 21.4823\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 21.3372 - val_loss: 21.1004\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 20.8801 - val_loss: 20.5928\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 20.2800 - val_loss: 19.9253\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 19.4900 - val_loss: 19.0296\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 18.4542 - val_loss: 17.8585\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 17.1758 - val_loss: 16.3589\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 15.5790 - val_loss: 14.6454\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 13.7471 - val_loss: 12.6056\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 11.6493 - val_loss: 10.4265\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 9.6267 - val_loss: 8.6159\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 8.2999 - val_loss: 7.9296\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 7.8479 - val_loss: 7.4010\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 7.3953 - val_loss: 6.8764\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 6.9801 - val_loss: 6.3762\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 6.4894 - val_loss: 5.9415\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 6.0472 - val_loss: 5.5245\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 5.5954 - val_loss: 5.0507\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 5.1286 - val_loss: 4.6779\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 4.8172 - val_loss: 4.3584\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 4.5502 - val_loss: 4.1049\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 4.3122 - val_loss: 3.9259\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 4.1433 - val_loss: 3.7423\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.9543 - val_loss: 3.5851\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.8096 - val_loss: 3.4558\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.6529 - val_loss: 3.3511\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.5516 - val_loss: 3.2564\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.4754 - val_loss: 3.2164\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 3.4150 - val_loss: 3.1763\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.3574 - val_loss: 3.1136\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 3.3168 - val_loss: 3.0434\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.2616 - val_loss: 2.9898\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.2354 - val_loss: 2.9631\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 3.1820 - val_loss: 2.9007\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 3.1352 - val_loss: 2.8675\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 0s 102us/step - loss: 3.1218 - val_loss: 2.8748\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.0750 - val_loss: 2.7620\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.0499 - val_loss: 2.7549\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.0253 - val_loss: 2.6920\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 0s 96us/step - loss: 2.9894 - val_loss: 2.6567\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 2.9630 - val_loss: 2.6161\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 2.9349 - val_loss: 2.5650\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 2.9082 - val_loss: 2.5432\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 2.8793 - val_loss: 2.5219\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 2.8528 - val_loss: 2.4864\n",
      "81/81 [==============================] - 0s 74us/step\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 21.7233 - val_loss: 21.4293\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 65us/step - loss: 21.0813 - val_loss: 20.7724\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 20.2776 - val_loss: 19.9375\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 19.2487 - val_loss: 18.8579\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 18.0116 - val_loss: 17.6053\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 16.5319 - val_loss: 16.1339\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 14.9164 - val_loss: 14.5732\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 13.3172 - val_loss: 13.0022\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 11.6489 - val_loss: 11.4471\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 9.8591 - val_loss: 9.9596\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 8.3301 - val_loss: 9.1293\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 7.7310 - val_loss: 8.5068\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 7.3795 - val_loss: 7.9703\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 6.9149 - val_loss: 7.4064\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 6.3970 - val_loss: 6.8822\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 5.9256 - val_loss: 6.1666\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 0s 96us/step - loss: 5.3969 - val_loss: 5.4154\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 0s 99us/step - loss: 4.8292 - val_loss: 4.8113\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 0s 102us/step - loss: 4.3587 - val_loss: 4.2596\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 0s 99us/step - loss: 3.9582 - val_loss: 3.8021\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 3.6586 - val_loss: 3.4495\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 0s 105us/step - loss: 3.5188 - val_loss: 3.2407\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 0s 108us/step - loss: 3.4452 - val_loss: 3.1702\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.3490 - val_loss: 3.0326\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 3.3390 - val_loss: 2.9780\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.2625 - val_loss: 2.9406\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - ETA: 0s - loss: 3.797 - 0s 102us/step - loss: 3.2120 - val_loss: 2.8530\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 0s 114us/step - loss: 3.1581 - val_loss: 2.7337\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 0s 105us/step - loss: 3.0871 - val_loss: 2.6402\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 0s 99us/step - loss: 3.0717 - val_loss: 2.6402\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 0s 117us/step - loss: 3.0058 - val_loss: 2.5763\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 2.9507 - val_loss: 2.5931\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 0s 124us/step - loss: 2.9154 - val_loss: 2.6050\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 0s 114us/step - loss: 2.8737 - val_loss: 2.5315\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 0s 108us/step - loss: 2.8420 - val_loss: 2.4717\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 2.8228 - val_loss: 2.3829\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 2.7753 - val_loss: 2.4536\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.7655 - val_loss: 2.3853\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 2.7082 - val_loss: 2.3553\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.7329 - val_loss: 2.3919\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 2.6487 - val_loss: 2.2265\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 2.6395 - val_loss: 2.2283\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.6185 - val_loss: 2.2781\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 2.5815 - val_loss: 2.1682\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 2.5856 - val_loss: 2.2392\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 2.5765 - val_loss: 2.2182\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 2.5049 - val_loss: 2.1747\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 0s 120us/step - loss: 2.4880 - val_loss: 2.1758\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 0s 99us/step - loss: 2.4855 - val_loss: 2.1709\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 2.4503 - val_loss: 2.1541\n",
      "81/81 [==============================] - 0s 98us/step\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 22.2523 - val_loss: 22.0901\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 22.0101 - val_loss: 21.8361\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 21.7182 - val_loss: 21.5372\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 21.3625 - val_loss: 21.1741\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 0s 49us/step - loss: 20.9349 - val_loss: 20.7258\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 0s 102us/step - loss: 20.3956 - val_loss: 20.1531\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 19.7252 - val_loss: 19.4088\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 0s 96us/step - loss: 18.8753 - val_loss: 18.4770\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 17.8513 - val_loss: 17.3279\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 0s 111us/step - loss: 16.6551 - val_loss: 15.9502\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 15.2733 - val_loss: 14.4707\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 13.6844 - val_loss: 12.7968\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 11.8763 - val_loss: 10.9376\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 9.9892 - val_loss: 9.4317\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - ETA: 0s - loss: 9.018 - 0s 74us/step - loss: 8.3933 - val_loss: 8.1399\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 7.4004 - val_loss: 7.2797\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 6.6794 - val_loss: 6.5393\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 6.1569 - val_loss: 5.9327\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 5.5927 - val_loss: 5.4301\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 5.1462 - val_loss: 4.9989\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 4.7969 - val_loss: 4.7371\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 4.5456 - val_loss: 4.5236\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 4.3084 - val_loss: 4.3222\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 4.1418 - val_loss: 4.2191\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 4.0452 - val_loss: 4.0797\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.9461 - val_loss: 3.9253\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 3.8437 - val_loss: 3.8327\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 3.7545 - val_loss: 3.7453\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.6866 - val_loss: 3.6768\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 77us/step - loss: 3.6773 - val_loss: 3.5992\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.5927 - val_loss: 3.4967\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.5089 - val_loss: 3.4305\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 0s 117us/step - loss: 3.4733 - val_loss: 3.3234\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 3.4358 - val_loss: 3.2974\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 0s 225us/step - loss: 3.3970 - val_loss: 3.2412\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 0s 102us/step - loss: 3.3402 - val_loss: 3.1646\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 0s 111us/step - loss: 3.3597 - val_loss: 3.1378\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.2922 - val_loss: 3.0283\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 0s 111us/step - loss: 3.2113 - val_loss: 3.0361\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 3.1945 - val_loss: 2.9435\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.1357 - val_loss: 2.8545\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.1134 - val_loss: 2.7991\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.0908 - val_loss: 2.7298\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 3.0230 - val_loss: 2.7411\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 2.9870 - val_loss: 2.6866\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 2.9614 - val_loss: 2.6473\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.9171 - val_loss: 2.6145\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 2.8711 - val_loss: 2.6047\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.8365 - val_loss: 2.5587\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 2.8113 - val_loss: 2.5324\n",
      "81/81 [==============================] - 0s 123us/step\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 22.3646 - val_loss: 22.2200\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 22.1764 - val_loss: 22.0298\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 21.9480 - val_loss: 21.8109\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 21.6732 - val_loss: 21.5358\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 21.3221 - val_loss: 21.1601\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 20.8385 - val_loss: 20.6330\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 20.1792 - val_loss: 19.8901\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 19.3224 - val_loss: 18.9363\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 18.2336 - val_loss: 17.7742\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 16.9622 - val_loss: 16.3361\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 15.5608 - val_loss: 14.4178\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 13.5635 - val_loss: 11.8103\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 10.7448 - val_loss: 9.2163\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 8.3449 - val_loss: 7.9189\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 7.4325 - val_loss: 7.2006\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 6.8147 - val_loss: 6.4128\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 6.0998 - val_loss: 5.7247\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 5.4922 - val_loss: 5.1711\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 5.0079 - val_loss: 4.6527\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 4.5472 - val_loss: 4.1574\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 4.2176 - val_loss: 3.8021\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.9428 - val_loss: 3.4830\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 3.7261 - val_loss: 3.2192\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 0s 96us/step - loss: 3.5402 - val_loss: 3.1322\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 0s 108us/step - loss: 3.4349 - val_loss: 3.0753\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.3466 - val_loss: 2.9158\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 0s 102us/step - loss: 3.2446 - val_loss: 2.8590\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 3.1681 - val_loss: 2.7578\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 3.1112 - val_loss: 2.7101\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 3.0537 - val_loss: 2.6789\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 0s 108us/step - loss: 3.1028 - val_loss: 2.6218\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 0s 117us/step - loss: 2.9499 - val_loss: 2.6684\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 0s 102us/step - loss: 2.9200 - val_loss: 2.5154\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - ETA: 0s - loss: 2.844 - 0s 114us/step - loss: 2.8862 - val_loss: 2.5530\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 0s 114us/step - loss: 2.8566 - val_loss: 2.5007\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 2.8212 - val_loss: 2.5170\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.7901 - val_loss: 2.3764\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 2.7915 - val_loss: 2.3154\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 0s 99us/step - loss: 2.7434 - val_loss: 2.3710\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 2.7005 - val_loss: 2.3999\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 0s 105us/step - loss: 2.6764 - val_loss: 2.2421\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.6970 - val_loss: 2.2192\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.6410 - val_loss: 2.2196\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 2.5962 - val_loss: 2.1216\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 2.5941 - val_loss: 2.1715\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.5688 - val_loss: 2.3198\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 2.5542 - val_loss: 2.0951\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.5160 - val_loss: 2.1473\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 2.5078 - val_loss: 2.1304\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 2.4742 - val_loss: 2.1311\n",
      "81/81 [==============================] - 0s 98us/step\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 22.5229 - val_loss: 22.3856\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 22.3452 - val_loss: 22.1931\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 22.1348 - val_loss: 21.9653\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 21.8723 - val_loss: 21.6714\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 0s 111us/step - loss: 21.5120 - val_loss: 21.2606\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 0s 96us/step - loss: 21.0263 - val_loss: 20.7336\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 20.3893 - val_loss: 20.0280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 19.5374 - val_loss: 19.0857\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 18.4385 - val_loss: 17.7941\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 0s 108us/step - loss: 16.9048 - val_loss: 16.1130\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 0s 96us/step - loss: 14.9428 - val_loss: 13.9815\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 12.5982 - val_loss: 12.0709\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 10.6358 - val_loss: 10.7046\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 9.3388 - val_loss: 9.7067\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 8.5245 - val_loss: 8.9326\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 0s 105us/step - loss: 7.9757 - val_loss: 8.2407\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 7.4246 - val_loss: 7.7122\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 6.9178 - val_loss: 7.1848\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 6.4437 - val_loss: 6.6564\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 5.9685 - val_loss: 6.0976\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 5.5016 - val_loss: 5.5180\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 5.0525 - val_loss: 5.0220\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 4.6191 - val_loss: 4.5690\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 4.2594 - val_loss: 4.1860\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.9999 - val_loss: 3.8840\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 3.8055 - val_loss: 3.6741\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 3.6940 - val_loss: 3.5055\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.5846 - val_loss: 3.3875\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.5534 - val_loss: 3.2519\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 0s 99us/step - loss: 3.4328 - val_loss: 3.1956\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.3825 - val_loss: 3.0856\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.3301 - val_loss: 3.0295\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 0s 99us/step - loss: 3.2837 - val_loss: 2.9835\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.2165 - val_loss: 2.9047\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 3.1805 - val_loss: 2.8458\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.1491 - val_loss: 2.8384\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 3.1428 - val_loss: 2.7593\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.0607 - val_loss: 2.7269\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 0s 99us/step - loss: 3.0333 - val_loss: 2.6632\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 3.0186 - val_loss: 2.6188\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 0s 102us/step - loss: 2.9615 - val_loss: 2.6296\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 2.9288 - val_loss: 2.5943\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.9022 - val_loss: 2.5733\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 2.8820 - val_loss: 2.4820\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.8570 - val_loss: 2.4657\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 2.8313 - val_loss: 2.4725\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.8009 - val_loss: 2.4008\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 2.7618 - val_loss: 2.4295\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.7480 - val_loss: 2.4117\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 2.7345 - val_loss: 2.3539\n",
      "81/81 [==============================] - 0s 135us/step\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 22.8455 - val_loss: 22.5885\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 22.5472 - val_loss: 22.3850\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 0s 105us/step - loss: 22.3512 - val_loss: 22.2286\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 0s 96us/step - loss: 22.1807 - val_loss: 22.0526\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 21.9802 - val_loss: 21.8289\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 21.7118 - val_loss: 21.5274\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 0s 108us/step - loss: 21.3517 - val_loss: 21.1192\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 20.8637 - val_loss: 20.5712\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 0s 114us/step - loss: 20.1964 - val_loss: 19.8322\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 0s 99us/step - loss: 19.3071 - val_loss: 18.8130\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 18.1106 - val_loss: 17.4020\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 16.5733 - val_loss: 15.7061\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 14.8316 - val_loss: 13.7467\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 12.7666 - val_loss: 11.4298\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 10.4468 - val_loss: 9.1479\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 0s 99us/step - loss: 8.2175 - val_loss: 7.4607\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 6.8252 - val_loss: 6.5085\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 6.1469 - val_loss: 5.8437\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 5.6192 - val_loss: 5.3791\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 5.1305 - val_loss: 4.8820\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 4.7212 - val_loss: 4.3766\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 4.4088 - val_loss: 4.0847\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 4.1516 - val_loss: 3.7735\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 3.9344 - val_loss: 3.6063\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 3.7589 - val_loss: 3.5027\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 0s 108us/step - loss: 3.6424 - val_loss: 3.4133\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 3.5871 - val_loss: 3.2470\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 3.4828 - val_loss: 3.1880\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.4455 - val_loss: 3.2034\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 0s 108us/step - loss: 3.3769 - val_loss: 3.1230\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 3.3094 - val_loss: 3.0671\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 0s 96us/step - loss: 3.2718 - val_loss: 2.9831\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.2293 - val_loss: 2.9509\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 3.1999 - val_loss: 2.8317\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 0s 114us/step - loss: 3.1545 - val_loss: 2.8117\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 0s 99us/step - loss: 3.1076 - val_loss: 2.7743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 3.0668 - val_loss: 2.7180\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 0s 99us/step - loss: 3.0175 - val_loss: 2.6907\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 0s 111us/step - loss: 2.9717 - val_loss: 2.6373\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 0s 105us/step - loss: 2.9390 - val_loss: 2.5863\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 2.9104 - val_loss: 2.5484\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 0s 105us/step - loss: 2.8718 - val_loss: 2.5696\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 0s 114us/step - loss: 2.8526 - val_loss: 2.5320\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 0s 111us/step - loss: 2.8028 - val_loss: 2.5200\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 0s 96us/step - loss: 2.7826 - val_loss: 2.5407\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 0s 117us/step - loss: 2.7563 - val_loss: 2.4752\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 0s 142us/step - loss: 2.7346 - val_loss: 2.4966\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 2.6948 - val_loss: 2.3490\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 0s 105us/step - loss: 2.6489 - val_loss: 2.3455\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 2.6276 - val_loss: 2.3046\n",
      "81/81 [==============================] - 0s 62us/step\n"
     ]
    }
   ],
   "source": [
    "# use for loop to run each combination\n",
    "for first_layer in [20,30]:\n",
    "    for second_layer in [12,18]:\n",
    "        for third_layer in [3,10]:\n",
    "            model = boston_model(first_layer,second_layer,third_layer)\n",
    "            # train the neural network, validation set is included to check if overfitting occurs\n",
    "            model.fit(x_train, y_train, epochs=50, validation_data=(x_valid, y_valid))\n",
    "            # get the performance by using validaiton set \n",
    "            mae = model.evaluate(x_valid, y_valid)\n",
    "            # record the details in the result dataframe \n",
    "            # use append() function \n",
    "            #result = result.append({'first_hidden':first_layer,'second_hidden':second_layer,'third_hidden':third_layer,'mae':mae}, ignore_index=True)\n",
    "            result=result.append({'first_hidden':first_layer,'second_hidden':second_layer,'third_hidden':third_layer,'mae':mae},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_hidden</th>\n",
       "      <th>second_hidden</th>\n",
       "      <th>third_hidden</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.572199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.349789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.486423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.154068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.532381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.131111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.353938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.304645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_hidden  second_hidden  third_hidden       mae\n",
       "0          20.0           12.0           3.0  2.572199\n",
       "1          20.0           12.0          10.0  2.349789\n",
       "2          20.0           18.0           3.0  2.486423\n",
       "3          20.0           18.0          10.0  2.154068\n",
       "4          30.0           12.0           3.0  2.532381\n",
       "5          30.0           12.0          10.0  2.131111\n",
       "6          30.0           18.0           3.0  2.353938\n",
       "7          30.0           18.0          10.0  2.304645"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we obtain the hyperparameters for the best combination by minimizing mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# first is to know which combination provides the minimized mae \n",
    "# use idxmin() function to check \n",
    "min_index = result['mae'].idxmin()\n",
    "# will return the index number \n",
    "print(min_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we obtain the numbers for the three hidden layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized number for the first layer is  30.0\n",
      "Optimized number for the second layer is  12.0\n",
      "Optimized number for the third layer is  10.0\n"
     ]
    }
   ],
   "source": [
    "first_hidden_best = result['first_hidden'][min_index]\n",
    "second_hidden_best = result['second_hidden'][min_index]\n",
    "third_hidden_best = result['third_hidden'][min_index]\n",
    "\n",
    "print(\"Optimized number for the first layer is \",first_hidden_best)\n",
    "print(\"Optimized number for the second layer is \",second_hidden_best)\n",
    "print(\"Optimized number for the third layer is \",third_hidden_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/100\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 22.8974 - val_loss: 22.5999\n",
      "Epoch 2/100\n",
      "323/323 [==============================] - 0s 86us/step - loss: 22.5690 - val_loss: 22.3542\n",
      "Epoch 3/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 22.3393 - val_loss: 22.1546\n",
      "Epoch 4/100\n",
      "323/323 [==============================] - 0s 83us/step - loss: 22.1199 - val_loss: 21.9162\n",
      "Epoch 5/100\n",
      "323/323 [==============================] - 0s 99us/step - loss: 21.8416 - val_loss: 21.5809\n",
      "Epoch 6/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 21.4299 - val_loss: 21.0591\n",
      "Epoch 7/100\n",
      "323/323 [==============================] - 0s 105us/step - loss: 20.7974 - val_loss: 20.2429\n",
      "Epoch 8/100\n",
      "323/323 [==============================] - 0s 102us/step - loss: 19.8144 - val_loss: 19.0521\n",
      "Epoch 9/100\n",
      "323/323 [==============================] - 0s 108us/step - loss: 18.3998 - val_loss: 17.4407\n",
      "Epoch 10/100\n",
      "323/323 [==============================] - 0s 151us/step - loss: 16.5862 - val_loss: 15.2891\n",
      "Epoch 11/100\n",
      "323/323 [==============================] - 0s 151us/step - loss: 14.2400 - val_loss: 12.6491\n",
      "Epoch 12/100\n",
      "323/323 [==============================] - 0s 114us/step - loss: 11.3629 - val_loss: 9.8856\n",
      "Epoch 13/100\n",
      "323/323 [==============================] - 0s 102us/step - loss: 8.6519 - val_loss: 8.1485\n",
      "Epoch 14/100\n",
      "323/323 [==============================] - 0s 111us/step - loss: 7.3499 - val_loss: 7.4430\n",
      "Epoch 15/100\n",
      "323/323 [==============================] - 0s 117us/step - loss: 6.9656 - val_loss: 6.8667\n",
      "Epoch 16/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 6.3500 - val_loss: 6.3242\n",
      "Epoch 17/100\n",
      "323/323 [==============================] - 0s 130us/step - loss: 5.7716 - val_loss: 5.7921\n",
      "Epoch 18/100\n",
      "323/323 [==============================] - 0s 133us/step - loss: 5.3391 - val_loss: 5.3721\n",
      "Epoch 19/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 5.0288 - val_loss: 5.0299\n",
      "Epoch 20/100\n",
      "323/323 [==============================] - 0s 120us/step - loss: 4.7266 - val_loss: 4.8526\n",
      "Epoch 21/100\n",
      "323/323 [==============================] - 0s 111us/step - loss: 4.5131 - val_loss: 4.5773\n",
      "Epoch 22/100\n",
      "323/323 [==============================] - 0s 102us/step - loss: 4.2763 - val_loss: 4.3460\n",
      "Epoch 23/100\n",
      "323/323 [==============================] - 0s 139us/step - loss: 4.1004 - val_loss: 4.1915\n",
      "Epoch 24/100\n",
      "323/323 [==============================] - 0s 105us/step - loss: 3.9895 - val_loss: 4.0456\n",
      "Epoch 25/100\n",
      "323/323 [==============================] - 0s 105us/step - loss: 3.9022 - val_loss: 3.9493\n",
      "Epoch 26/100\n",
      "323/323 [==============================] - 0s 68us/step - loss: 3.8229 - val_loss: 3.8733\n",
      "Epoch 27/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.7572 - val_loss: 3.7877\n",
      "Epoch 28/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 3.7231 - val_loss: 3.7089\n",
      "Epoch 29/100\n",
      "323/323 [==============================] - 0s 108us/step - loss: 3.6523 - val_loss: 3.6396\n",
      "Epoch 30/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 3.6127 - val_loss: 3.6042\n",
      "Epoch 31/100\n",
      "323/323 [==============================] - 0s 105us/step - loss: 3.5062 - val_loss: 3.5050\n",
      "Epoch 32/100\n",
      "323/323 [==============================] - 0s 136us/step - loss: 3.5065 - val_loss: 3.4257\n",
      "Epoch 33/100\n",
      "323/323 [==============================] - 0s 114us/step - loss: 3.4316 - val_loss: 3.3700\n",
      "Epoch 34/100\n",
      "323/323 [==============================] - 0s 120us/step - loss: 3.3955 - val_loss: 3.2972\n",
      "Epoch 35/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 3.3637 - val_loss: 3.2939\n",
      "Epoch 36/100\n",
      "323/323 [==============================] - 0s 139us/step - loss: 3.2947 - val_loss: 3.1960\n",
      "Epoch 37/100\n",
      "323/323 [==============================] - 0s 130us/step - loss: 3.3162 - val_loss: 3.1547\n",
      "Epoch 38/100\n",
      "323/323 [==============================] - 0s 124us/step - loss: 3.2165 - val_loss: 3.1993\n",
      "Epoch 39/100\n",
      "323/323 [==============================] - 0s 114us/step - loss: 3.1949 - val_loss: 3.1736\n",
      "Epoch 40/100\n",
      "323/323 [==============================] - 0s 130us/step - loss: 3.1578 - val_loss: 3.1251\n",
      "Epoch 41/100\n",
      "323/323 [==============================] - 0s 127us/step - loss: 3.1056 - val_loss: 2.9897\n",
      "Epoch 42/100\n",
      "323/323 [==============================] - 0s 111us/step - loss: 3.0684 - val_loss: 2.9558\n",
      "Epoch 43/100\n",
      "323/323 [==============================] - 0s 185us/step - loss: 3.0257 - val_loss: 2.8985\n",
      "Epoch 44/100\n",
      "323/323 [==============================] - 0s 83us/step - loss: 3.0093 - val_loss: 2.9386\n",
      "Epoch 45/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 2.9735 - val_loss: 2.8278\n",
      "Epoch 46/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 2.8893 - val_loss: 2.8404\n",
      "Epoch 47/100\n",
      "323/323 [==============================] - 0s 86us/step - loss: 2.8838 - val_loss: 2.7734\n",
      "Epoch 48/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 2.8677 - val_loss: 2.7172\n",
      "Epoch 49/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 2.7910 - val_loss: 2.7190\n",
      "Epoch 50/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 2.7762 - val_loss: 2.6380\n",
      "Epoch 51/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 2.7340 - val_loss: 2.6188\n",
      "Epoch 52/100\n",
      "323/323 [==============================] - 0s 117us/step - loss: 2.6989 - val_loss: 2.5768\n",
      "Epoch 53/100\n",
      "323/323 [==============================] - 0s 86us/step - loss: 2.7396 - val_loss: 2.5191\n",
      "Epoch 54/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 2.6618 - val_loss: 2.5368\n",
      "Epoch 55/100\n",
      "323/323 [==============================] - 0s 130us/step - loss: 2.6717 - val_loss: 2.5401\n",
      "Epoch 56/100\n",
      "323/323 [==============================] - 0s 99us/step - loss: 2.6184 - val_loss: 2.4252\n",
      "Epoch 57/100\n",
      "323/323 [==============================] - 0s 102us/step - loss: 2.5855 - val_loss: 2.4784\n",
      "Epoch 58/100\n",
      "323/323 [==============================] - 0s 102us/step - loss: 2.5505 - val_loss: 2.3586\n",
      "Epoch 59/100\n",
      "323/323 [==============================] - 0s 108us/step - loss: 2.5205 - val_loss: 2.3736\n",
      "Epoch 60/100\n",
      "323/323 [==============================] - 0s 130us/step - loss: 2.4869 - val_loss: 2.2910\n",
      "Epoch 61/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 2.4702 - val_loss: 2.2596\n",
      "Epoch 62/100\n",
      "323/323 [==============================] - 0s 108us/step - loss: 2.4455 - val_loss: 2.2882\n",
      "Epoch 63/100\n",
      "323/323 [==============================] - 0s 108us/step - loss: 2.4240 - val_loss: 2.2246\n",
      "Epoch 64/100\n",
      "323/323 [==============================] - 0s 108us/step - loss: 2.4001 - val_loss: 2.2680\n",
      "Epoch 65/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 2.4181 - val_loss: 2.2439\n",
      "Epoch 66/100\n",
      "323/323 [==============================] - 0s 86us/step - loss: 2.3866 - val_loss: 2.1749\n",
      "Epoch 67/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 2.291 - 0s 96us/step - loss: 2.3578 - val_loss: 2.2427\n",
      "Epoch 68/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 2.3176 - val_loss: 2.1585\n",
      "Epoch 69/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 2.2982 - val_loss: 2.1912\n",
      "Epoch 70/100\n",
      "323/323 [==============================] - 0s 120us/step - loss: 2.2932 - val_loss: 2.1421\n",
      "Epoch 71/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 2.2796 - val_loss: 2.1991\n",
      "Epoch 72/100\n",
      "323/323 [==============================] - 0s 139us/step - loss: 2.2815 - val_loss: 2.1461\n",
      "Epoch 73/100\n",
      "323/323 [==============================] - 0s 83us/step - loss: 2.2801 - val_loss: 2.1121\n",
      "Epoch 74/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 2.2361 - val_loss: 2.2085\n",
      "Epoch 75/100\n",
      "323/323 [==============================] - 0s 74us/step - loss: 2.2533 - val_loss: 2.1037\n",
      "Epoch 76/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 2.2539 - val_loss: 2.0760\n",
      "Epoch 77/100\n",
      "323/323 [==============================] - 0s 96us/step - loss: 2.2602 - val_loss: 2.1615\n",
      "Epoch 78/100\n",
      "323/323 [==============================] - 0s 117us/step - loss: 2.2076 - val_loss: 2.0814\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 102us/step - loss: 2.1874 - val_loss: 2.1500\n",
      "Epoch 80/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 2.1663 - val_loss: 2.0524\n",
      "Epoch 81/100\n",
      "323/323 [==============================] - 0s 102us/step - loss: 2.1844 - val_loss: 2.1260\n",
      "Epoch 82/100\n",
      "323/323 [==============================] - 0s 176us/step - loss: 2.1354 - val_loss: 2.0698\n",
      "Epoch 83/100\n",
      "323/323 [==============================] - 0s 108us/step - loss: 2.1424 - val_loss: 2.0469\n",
      "Epoch 84/100\n",
      "323/323 [==============================] - 0s 173us/step - loss: 2.1284 - val_loss: 2.0720\n",
      "Epoch 85/100\n",
      "323/323 [==============================] - 0s 108us/step - loss: 2.1153 - val_loss: 2.0399\n",
      "Epoch 86/100\n",
      "323/323 [==============================] - 0s 108us/step - loss: 2.1323 - val_loss: 2.0941\n",
      "Epoch 87/100\n",
      "323/323 [==============================] - 0s 130us/step - loss: 2.1272 - val_loss: 2.0911\n",
      "Epoch 88/100\n",
      "323/323 [==============================] - 0s 108us/step - loss: 2.1035 - val_loss: 2.0679\n",
      "Epoch 89/100\n",
      "323/323 [==============================] - 0s 120us/step - loss: 2.0918 - val_loss: 2.0439\n",
      "Epoch 90/100\n",
      "323/323 [==============================] - 0s 136us/step - loss: 2.0829 - val_loss: 2.0473\n",
      "Epoch 91/100\n",
      "323/323 [==============================] - 0s 111us/step - loss: 2.0978 - val_loss: 2.0352\n",
      "Epoch 92/100\n",
      "323/323 [==============================] - 0s 90us/step - loss: 2.0861 - val_loss: 2.0098\n",
      "Epoch 93/100\n",
      "323/323 [==============================] - 0s 83us/step - loss: 2.0642 - val_loss: 2.0289\n",
      "Epoch 94/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 2.0442 - val_loss: 2.0163\n",
      "Epoch 95/100\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.0459 - val_loss: 2.0216\n",
      "Epoch 96/100\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.0297 - val_loss: 1.9994\n",
      "Epoch 97/100\n",
      "323/323 [==============================] - 0s 93us/step - loss: 2.0271 - val_loss: 2.0073\n",
      "Epoch 98/100\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.0175 - val_loss: 1.9724\n",
      "Epoch 99/100\n",
      "323/323 [==============================] - 0s 80us/step - loss: 2.0541 - val_loss: 1.9849\n",
      "Epoch 100/100\n",
      "323/323 [==============================] - 0s 77us/step - loss: 2.0279 - val_loss: 2.0140\n",
      "102/102 [==============================] - 0s 68us/step\n",
      "Mean absolute Error for the test set:  2.7364203906526754\n"
     ]
    }
   ],
   "source": [
    "# first, change the hidden_best from float back to integer\n",
    "first_hidden_best  = int(first_hidden_best)\n",
    "second_hidden_best = int(second_hidden_best)\n",
    "third_hidden_best  = int(third_hidden_best)\n",
    "\n",
    "# then train the model again, this time epochs = 50\n",
    "min_model = boston_model(first_hidden_best,second_hidden_best,third_hidden_best)\n",
    "min_model.fit(x_train, y_train, epochs=50, validation_data=(x_valid, y_valid))\n",
    "min_mae = min_model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"Mean absolute Error for the test set: \", min_mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
