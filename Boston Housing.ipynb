{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston housing price regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import modules \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from keras\n",
    "First step is to import boston housing data from kears.\n",
    "<br>The format is in array.\n",
    "<br>Training set and test set are separated based on seed(optional).\n",
    "<br>Input housing features and output housing prices are also separated.\n",
    "<br>Further information about the usage, please visit https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boston housing data from keras\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.boston_housing.load_data(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.1780e-02, 0.0000e+00, 4.0500e+00, ..., 1.6600e+01, 3.9550e+02,\n",
       "        9.0400e+00],\n",
       "       [5.6440e-02, 4.0000e+01, 6.4100e+00, ..., 1.7600e+01, 3.9690e+02,\n",
       "        3.5300e+00],\n",
       "       [1.0574e-01, 0.0000e+00, 2.7740e+01, ..., 2.0100e+01, 3.9011e+02,\n",
       "        1.8070e+01],\n",
       "       ...,\n",
       "       [3.0410e-02, 0.0000e+00, 5.1900e+00, ..., 2.0200e+01, 3.9481e+02,\n",
       "        1.0560e+01],\n",
       "       [5.2058e-01, 0.0000e+00, 6.2000e+00, ..., 1.7400e+01, 3.8845e+02,\n",
       "        9.5400e+00],\n",
       "       [2.5199e-01, 0.0000e+00, 1.0590e+01, ..., 1.8600e+01, 3.8943e+02,\n",
       "        1.8060e+01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize input features\n",
    "Because the input features are in different scales, it is necessary to normalize the input features so that they share the same scales\n",
    "<br>sklearn.preprocessing.StandardScaler is used to normalize\n",
    "<br>DO NOT mix with sklearn.preprocessing.normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement StandardScaler to normalize features\n",
    "scaler = StandardScaler()\n",
    "# use fit_transform to obtain mean and variance for x_train (fit) and then normalize x_train (transform)\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "# use transform to normalize x_test \n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate validation set from original training set \n",
    "Use sklearn.model_selection.train_test_split to separate \n",
    "<br>Assign test_size or train_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate validation set from original training set\n",
    "# use train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train,y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build neural network\n",
    "Use a function to build this neural network with three hidden layers\n",
    "<br>This function use the numbers of neurons in each hidden layer as parameter (in total three input parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build neural network\n",
    "\n",
    "def boston_model(n_first,n_second,n_third):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # input layer\n",
    "    model.add(Dense(n_first,activation='relu',input_dim=x_train.shape[1])) \n",
    "    # input_shape can also be used to input the shape for input data \n",
    "    # model.add(Dense(n_first,activation='relu',input_shape = (x_train.shape[1],)))\n",
    "    \n",
    "    # hidden layers\n",
    "        # second layer\n",
    "    model.add(Dense(n_second,activation='relu')) # no need to specify input_dim in hidden layers\n",
    "        # third layer\n",
    "    model.add(Dense(n_third, activation='relu'))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(1)) # Since default activation function is linear/identy, no need to define\n",
    "    # compilation\n",
    "    model.compile(optimizer='adam',loss='mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter selection\n",
    "Use dataframe to store the mae for validation under different combinations of neurons \n",
    "<br>This dataframe will then be used to find the best case and then use this combination to predict the outcome for test set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First is to create a dataframe to store result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=['first_hidden','second_hidden','third_hidden','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 4 columns):\n",
      "first_hidden     0 non-null object\n",
      "second_hidden    0 non-null object\n",
      "third_hidden     0 non-null object\n",
      "mae              0 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second is to train the model and get the mae from validation set \n",
    "<br>Parameters to be tested for each layer: \n",
    "<br>First layer: 20,30\n",
    "<br>Second layer: 12,18\n",
    "<br>Third layer: 3,10\n",
    "<br>In total 8 combinations\n",
    "<br><br>For each combination, epochs =30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yuasto\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Yuasto\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 22.4274 - val_loss: 22.3159\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 22.2478 - val_loss: 22.1425\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 0s 49us/step - loss: 22.0488 - val_loss: 21.9382\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 21.8144 - val_loss: 21.6912\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 21.5288 - val_loss: 21.3620\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 21.1452 - val_loss: 20.9317\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 20.6439 - val_loss: 20.3634\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 19.9915 - val_loss: 19.6404\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 19.1748 - val_loss: 18.7171\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 18.1271 - val_loss: 17.5467\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 16.8687 - val_loss: 16.1065\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 15.3308 - val_loss: 14.3256\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 13.5461 - val_loss: 12.4146\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 0s 49us/step - loss: 11.6418 - val_loss: 10.5943\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 9.9139 - val_loss: 9.0548\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 0s 46us/step - loss: 8.6384 - val_loss: 8.1517\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 7.9052 - val_loss: 7.4801\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 7.3149 - val_loss: 6.9657\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 0s 49us/step - loss: 6.8286 - val_loss: 6.5200\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 6.4031 - val_loss: 6.0733\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 6.0064 - val_loss: 5.6813\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 0s 49us/step - loss: 5.6749 - val_loss: 5.3300\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 5.3896 - val_loss: 5.0331\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 5.1230 - val_loss: 4.7278\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 4.8466 - val_loss: 4.4840\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 4.6309 - val_loss: 4.2757\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 4.4415 - val_loss: 4.0828\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 4.2927 - val_loss: 3.9188\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 0s 108us/step - loss: 4.1222 - val_loss: 3.7946\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 3.9697 - val_loss: 3.6492\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 0s 117us/step - loss: 3.8352 - val_loss: 3.5415\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 3.6895 - val_loss: 3.4415\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.5978 - val_loss: 3.3905\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.5206 - val_loss: 3.3036\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.4441 - val_loss: 3.2282\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.3812 - val_loss: 3.1777\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 3.3070 - val_loss: 3.1302\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 3.2650 - val_loss: 3.0754\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 3.2031 - val_loss: 2.9940\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 3.1527 - val_loss: 2.9127\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 3.1208 - val_loss: 2.9106\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.0582 - val_loss: 2.8364\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 0s 93us/step - loss: 3.0214 - val_loss: 2.8084\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.9937 - val_loss: 2.7553\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.9409 - val_loss: 2.7087\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.9079 - val_loss: 2.7052\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.8807 - val_loss: 2.6246\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 2.8616 - val_loss: 2.6191\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.8221 - val_loss: 2.6248\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 2.8040 - val_loss: 2.5628\n",
      "81/81 [==============================] - 0s 49us/step\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 4ms/step - loss: 23.0024 - val_loss: 22.7477\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 22.7317 - val_loss: 22.4871\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 22.4481 - val_loss: 22.2166\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 22.1383 - val_loss: 21.9027\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 21.7775 - val_loss: 21.5170\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 21.3267 - val_loss: 21.0120\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 20.7243 - val_loss: 20.3206\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 19.9046 - val_loss: 19.3854\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 18.8122 - val_loss: 18.1249\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 17.3573 - val_loss: 16.4414\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 15.5316 - val_loss: 14.3416\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 13.3032 - val_loss: 11.9407\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 10.8869 - val_loss: 9.7651\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 8.7945 - val_loss: 8.0736\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 7.6467 - val_loss: 7.3686\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 7.2305 - val_loss: 6.7883\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 6.7160 - val_loss: 6.2697\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 6.1828 - val_loss: 5.8080\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 5.7131 - val_loss: 5.3620\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 5.2572 - val_loss: 4.9121\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 4.8597 - val_loss: 4.5953\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 4.5181 - val_loss: 4.3727\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 4.2709 - val_loss: 4.1695\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 80us/step - loss: 4.1013 - val_loss: 4.0487\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.9681 - val_loss: 3.9082\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.8658 - val_loss: 3.7317\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.7623 - val_loss: 3.6205\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.6587 - val_loss: 3.5068\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 3.5836 - val_loss: 3.4236\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 3.5031 - val_loss: 3.3763\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 3.4462 - val_loss: 3.3212\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.3875 - val_loss: 3.2625\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.3350 - val_loss: 3.2269\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.2771 - val_loss: 3.1307\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.2301 - val_loss: 3.0660\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 3.1844 - val_loss: 3.0198\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 0s 102us/step - loss: 3.1376 - val_loss: 2.9471\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 3.1071 - val_loss: 2.8858\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 3.0543 - val_loss: 2.8544\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 0s 99us/step - loss: 3.0081 - val_loss: 2.7958\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 2.9619 - val_loss: 2.7110\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 0s 108us/step - loss: 2.9202 - val_loss: 2.6457\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 0s 154us/step - loss: 2.8701 - val_loss: 2.6014\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 0s 96us/step - loss: 2.8435 - val_loss: 2.5282\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 2.8233 - val_loss: 2.5061\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 2.7717 - val_loss: 2.4922\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 2.7379 - val_loss: 2.4462\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 0s 102us/step - loss: 2.6883 - val_loss: 2.4108\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 2.6859 - val_loss: 2.3555\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 2.6513 - val_loss: 2.3359\n",
      "81/81 [==============================] - 0s 62us/step\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 22.4814 - val_loss: 22.3870\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 22.3915 - val_loss: 22.2836\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 22.2759 - val_loss: 22.1512\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 22.1249 - val_loss: 21.9839\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 21.9288 - val_loss: 21.7679\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 21.6744 - val_loss: 21.4822\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 21.3370 - val_loss: 21.1001\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 20.8796 - val_loss: 20.5922\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 20.2792 - val_loss: 19.9247\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 19.4894 - val_loss: 19.0291\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 18.4537 - val_loss: 17.8582\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 17.1755 - val_loss: 16.3588\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 15.5792 - val_loss: 14.6469\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 13.7490 - val_loss: 12.6078\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 0s 49us/step - loss: 11.6515 - val_loss: 10.4286\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 9.6295 - val_loss: 8.6176\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 8.3008 - val_loss: 7.9300\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 7.8512 - val_loss: 7.4023\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 7.3999 - val_loss: 6.8773\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 6.9822 - val_loss: 6.3797\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 6.4922 - val_loss: 5.9461\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 6.0511 - val_loss: 5.5298\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 5.6000 - val_loss: 5.0556\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 5.1317 - val_loss: 4.6814\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 4.8185 - val_loss: 4.3599\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 4.5515 - val_loss: 4.1068\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 4.3145 - val_loss: 3.9285\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 4.1458 - val_loss: 3.7459\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 3.9566 - val_loss: 3.5843\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.8090 - val_loss: 3.4562\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.6533 - val_loss: 3.3515\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 3.5519 - val_loss: 3.2592\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 3.4745 - val_loss: 3.2103\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.4120 - val_loss: 3.1711\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.3551 - val_loss: 3.1072\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 3.3126 - val_loss: 3.0372\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.2591 - val_loss: 2.9832\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 3.2326 - val_loss: 2.9564\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.1795 - val_loss: 2.9026\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.1358 - val_loss: 2.8541\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.1163 - val_loss: 2.8648\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.0715 - val_loss: 2.7570\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 0s 43us/step - loss: 3.0487 - val_loss: 2.7506\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.0243 - val_loss: 2.6847\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.9895 - val_loss: 2.6508\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 2.9613 - val_loss: 2.6093\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 2.9319 - val_loss: 2.5567\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 2.9055 - val_loss: 2.5375\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 2.8775 - val_loss: 2.5116\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 2.8488 - val_loss: 2.4749\n",
      "81/81 [==============================] - 0s 86us/step\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 21.7232 - val_loss: 21.4280\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 65us/step - loss: 21.0802 - val_loss: 20.7726\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 20.2781 - val_loss: 19.9371\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 19.2485 - val_loss: 18.8590\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 18.0135 - val_loss: 17.6076\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 16.5345 - val_loss: 16.1372\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 14.9200 - val_loss: 14.5775\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 0s 53us/step - loss: 13.3221 - val_loss: 13.0072\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 11.6550 - val_loss: 11.4525\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 9.8665 - val_loss: 9.9645\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 8.3340 - val_loss: 9.1322\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 7.7320 - val_loss: 8.5087\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 7.3796 - val_loss: 7.9732\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 6.9153 - val_loss: 7.4095\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 6.3976 - val_loss: 6.8842\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 5.9261 - val_loss: 6.1682\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 5.3967 - val_loss: 5.4165\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 4.8288 - val_loss: 4.8112\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 4.3590 - val_loss: 4.2591\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 3.9576 - val_loss: 3.7985\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.6542 - val_loss: 3.4438\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.5179 - val_loss: 3.2418\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 0s 49us/step - loss: 3.4396 - val_loss: 3.1731\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.3461 - val_loss: 3.0369\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.3281 - val_loss: 2.9822\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.2656 - val_loss: 2.9516\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.2200 - val_loss: 2.8702\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.1712 - val_loss: 2.7501\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.0880 - val_loss: 2.6452\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.0819 - val_loss: 2.6194\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.0068 - val_loss: 2.5741\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 2.9490 - val_loss: 2.6022\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.9151 - val_loss: 2.6030\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 2.8732 - val_loss: 2.5338\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.8423 - val_loss: 2.4722\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 2.8254 - val_loss: 2.3877\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.7773 - val_loss: 2.4511\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.7652 - val_loss: 2.3897\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 2.7124 - val_loss: 2.3616\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 2.7370 - val_loss: 2.3968\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 2.6528 - val_loss: 2.2326\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 2.6465 - val_loss: 2.2359\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.6272 - val_loss: 2.2883\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.5878 - val_loss: 2.1740\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 2.5912 - val_loss: 2.2550\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 0s 49us/step - loss: 2.5826 - val_loss: 2.2149\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 2.5077 - val_loss: 2.1794\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 2.4917 - val_loss: 2.1807\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.4986 - val_loss: 2.1770\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.4579 - val_loss: 2.1695\n",
      "81/81 [==============================] - 0s 62us/step\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 22.2524 - val_loss: 22.0904\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 22.0105 - val_loss: 21.8365\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 0s 49us/step - loss: 21.7189 - val_loss: 21.5380\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 21.3636 - val_loss: 21.1748\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 20.9357 - val_loss: 20.7273\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 0s 49us/step - loss: 20.3974 - val_loss: 20.1559\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 0s 53us/step - loss: 19.7285 - val_loss: 19.4134\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 18.8804 - val_loss: 18.4833\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 17.8587 - val_loss: 17.3370\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 16.6650 - val_loss: 15.9617\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 15.2851 - val_loss: 14.4828\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 13.6987 - val_loss: 12.8087\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 11.8895 - val_loss: 10.9468\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 10.0019 - val_loss: 9.4407\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 8.4056 - val_loss: 8.1464\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 7.4069 - val_loss: 7.2838\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 6.6833 - val_loss: 6.5435\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 6.1597 - val_loss: 5.9387\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 5.5952 - val_loss: 5.4302\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 5.1473 - val_loss: 4.9991\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 0s 49us/step - loss: 4.7973 - val_loss: 4.7336\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 4.5454 - val_loss: 4.5214\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 4.3097 - val_loss: 4.3212\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 4.1425 - val_loss: 4.2203\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 4.0476 - val_loss: 4.0814\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.9478 - val_loss: 3.9262\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.8462 - val_loss: 3.8329\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.7557 - val_loss: 3.7467\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.6875 - val_loss: 3.6769\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.6758 - val_loss: 3.5966\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 56us/step - loss: 3.5908 - val_loss: 3.4946\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.5097 - val_loss: 3.4327\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.4757 - val_loss: 3.3274\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.4342 - val_loss: 3.2953\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.3960 - val_loss: 3.2489\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.3425 - val_loss: 3.1661\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.3669 - val_loss: 3.1509\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.3031 - val_loss: 3.0340\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.2140 - val_loss: 3.0423\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.1963 - val_loss: 2.9518\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.1418 - val_loss: 2.8561\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.1147 - val_loss: 2.8038\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 3.0955 - val_loss: 2.7272\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 3.0217 - val_loss: 2.7474\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 2.9871 - val_loss: 2.6894\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 2.9711 - val_loss: 2.6648\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.9180 - val_loss: 2.6257\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.8696 - val_loss: 2.5985\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 2.8317 - val_loss: 2.5593\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 2.8048 - val_loss: 2.5383\n",
      "81/81 [==============================] - 0s 74us/step\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 22.3603 - val_loss: 22.2144\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 22.1698 - val_loss: 22.0237\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 21.9404 - val_loss: 21.8033\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 21.6637 - val_loss: 21.5262\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 21.3097 - val_loss: 21.1472\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 20.8223 - val_loss: 20.6153\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 20.1606 - val_loss: 19.8710\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 19.3008 - val_loss: 18.9115\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 18.2050 - val_loss: 17.7441\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 16.9274 - val_loss: 16.2916\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 15.5124 - val_loss: 14.3432\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 13.4757 - val_loss: 11.7138\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 10.6361 - val_loss: 9.1634\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 0s 102us/step - loss: 8.2922 - val_loss: 7.9125\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 7.4154 - val_loss: 7.1959\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 6.8012 - val_loss: 6.4222\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 6.1036 - val_loss: 5.7378\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 5.4943 - val_loss: 5.1824\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 5.0077 - val_loss: 4.6659\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 4.5506 - val_loss: 4.1698\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 4.2189 - val_loss: 3.8063\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.9441 - val_loss: 3.4872\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.7299 - val_loss: 3.2240\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.5457 - val_loss: 3.1312\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.4317 - val_loss: 3.0637\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.3423 - val_loss: 2.9087\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.2489 - val_loss: 2.8442\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.1674 - val_loss: 2.7517\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 3.1051 - val_loss: 2.7075\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.0512 - val_loss: 2.6787\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.0928 - val_loss: 2.6184\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 2.9458 - val_loss: 2.6304\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.9093 - val_loss: 2.5131\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.8804 - val_loss: 2.5414\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 2.8534 - val_loss: 2.5126\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 0s 96us/step - loss: 2.8276 - val_loss: 2.5345\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.7888 - val_loss: 2.3831\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 2.7909 - val_loss: 2.3181\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 2.7400 - val_loss: 2.3602\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 2.7002 - val_loss: 2.4022\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 2.6741 - val_loss: 2.2439\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.6887 - val_loss: 2.2151\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 2.6346 - val_loss: 2.2327\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.5895 - val_loss: 2.1158\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 2.5914 - val_loss: 2.1651\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 2.5603 - val_loss: 2.3124\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 2.5471 - val_loss: 2.0948\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 0s 86us/step - loss: 2.5099 - val_loss: 2.1363\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.5072 - val_loss: 2.1094\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 2.4704 - val_loss: 2.1502\n",
      "81/81 [==============================] - 0s 99us/step\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 22.5229 - val_loss: 22.3856\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 22.3454 - val_loss: 22.1935\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 22.1353 - val_loss: 21.9656\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 21.8726 - val_loss: 21.6711\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 0s 49us/step - loss: 21.5118 - val_loss: 21.2605\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 21.0265 - val_loss: 20.7343\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 20.3900 - val_loss: 20.0288\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 19.5383 - val_loss: 19.0860\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 56us/step - loss: 18.4387 - val_loss: 17.7951\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 16.9056 - val_loss: 16.1147\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 14.9453 - val_loss: 13.9858\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 12.6036 - val_loss: 12.0762\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 10.6408 - val_loss: 10.7064\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 9.3408 - val_loss: 9.7067\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 0s 90us/step - loss: 8.5282 - val_loss: 8.9319\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 7.9796 - val_loss: 8.2389\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 7.4262 - val_loss: 7.7066\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 6.9140 - val_loss: 7.1805\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 6.4409 - val_loss: 6.6566\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 5.9641 - val_loss: 6.0912\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 5.4979 - val_loss: 5.5137\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 5.0477 - val_loss: 5.0176\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 4.6147 - val_loss: 4.5682\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 4.2586 - val_loss: 4.1915\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 4.0037 - val_loss: 3.8894\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.8069 - val_loss: 3.6765\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.6995 - val_loss: 3.5121\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.5831 - val_loss: 3.3917\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.5537 - val_loss: 3.2596\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.4317 - val_loss: 3.1963\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.3790 - val_loss: 3.0897\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.3318 - val_loss: 3.0334\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.2846 - val_loss: 2.9856\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.2162 - val_loss: 2.9067\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.1803 - val_loss: 2.8493\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.1467 - val_loss: 2.8367\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.1383 - val_loss: 2.7592\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.0611 - val_loss: 2.7263\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.0328 - val_loss: 2.6654\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.0158 - val_loss: 2.6206\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 2.9609 - val_loss: 2.6206\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 2.9276 - val_loss: 2.5857\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.9050 - val_loss: 2.5851\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.8744 - val_loss: 2.4817\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.8517 - val_loss: 2.4691\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 2.8272 - val_loss: 2.4696\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.7997 - val_loss: 2.4082\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 2.7574 - val_loss: 2.4250\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.7427 - val_loss: 2.4111\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 2.7334 - val_loss: 2.3558\n",
      "81/81 [==============================] - 0s 62us/step\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 22.8442 - val_loss: 22.5862\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 22.5452 - val_loss: 22.3841\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 22.3504 - val_loss: 22.2282\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 22.1805 - val_loss: 22.0527\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 21.9804 - val_loss: 21.8295\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 21.7125 - val_loss: 21.5281\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 21.3528 - val_loss: 21.1203\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 20.8653 - val_loss: 20.5729\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 0s 46us/step - loss: 20.1989 - val_loss: 19.8351\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 19.3121 - val_loss: 18.8205\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 18.1206 - val_loss: 17.4137\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 16.5856 - val_loss: 15.7194\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 14.8465 - val_loss: 13.7643\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 12.7840 - val_loss: 11.4504\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 0s 99us/step - loss: 10.4724 - val_loss: 9.1696\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 8.2363 - val_loss: 7.4699\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 6.8355 - val_loss: 6.5208\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 6.1489 - val_loss: 5.8575\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 5.6265 - val_loss: 5.3884\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 5.1363 - val_loss: 4.8946\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 4.7258 - val_loss: 4.3944\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 4.4182 - val_loss: 4.0882\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 4.1574 - val_loss: 3.7768\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.9346 - val_loss: 3.6104\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.7579 - val_loss: 3.5065\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.6426 - val_loss: 3.4151\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.5905 - val_loss: 3.2419\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.4783 - val_loss: 3.1712\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.4347 - val_loss: 3.1871\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.3667 - val_loss: 3.1101\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.2993 - val_loss: 3.0601\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 3.2650 - val_loss: 2.9745\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.2369 - val_loss: 2.9347\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.2084 - val_loss: 2.8311\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.1609 - val_loss: 2.8018\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 3.1108 - val_loss: 2.7676\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.0650 - val_loss: 2.7206\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 56us/step - loss: 3.0212 - val_loss: 2.6966\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.9724 - val_loss: 2.6394\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 2.9378 - val_loss: 2.5885\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 2.9059 - val_loss: 2.5551\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.8696 - val_loss: 2.5589\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.8455 - val_loss: 2.5378\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.8004 - val_loss: 2.5378\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 2.7801 - val_loss: 2.5518\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.7546 - val_loss: 2.4784\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 2.7276 - val_loss: 2.4979\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.6902 - val_loss: 2.3602\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.6433 - val_loss: 2.3583\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.6317 - val_loss: 2.3735\n",
      "81/81 [==============================] - 0s 62us/step\n"
     ]
    }
   ],
   "source": [
    "# use for loop to run each combination\n",
    "for first_layer in [20,30]:\n",
    "    for second_layer in [12,18]:\n",
    "        for third_layer in [3,10]:\n",
    "            model = boston_model(first_layer,second_layer,third_layer)\n",
    "            # train the neural network, validation set is included to check if overfitting occurs\n",
    "            model.fit(x_train, y_train, epochs=50, validation_data=(x_valid, y_valid))\n",
    "            # get the performance by using validaiton set \n",
    "            mae = model.evaluate(x_valid, y_valid)\n",
    "            # record the details in the result dataframe \n",
    "            # use append() function \n",
    "            #result = result.append({'first_hidden':first_layer,'second_hidden':second_layer,'third_hidden':third_layer,'mae':mae}, ignore_index=True)\n",
    "            result=result.append({'first_hidden':first_layer,'second_hidden':second_layer,'third_hidden':third_layer,'mae':mae},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_hidden</th>\n",
       "      <th>second_hidden</th>\n",
       "      <th>third_hidden</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.562792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.335937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.474858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.169455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.538287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.150151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.355836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.373490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_hidden  second_hidden  third_hidden       mae\n",
       "0          20.0           12.0           3.0  2.562792\n",
       "1          20.0           12.0          10.0  2.335937\n",
       "2          20.0           18.0           3.0  2.474858\n",
       "3          20.0           18.0          10.0  2.169455\n",
       "4          30.0           12.0           3.0  2.538287\n",
       "5          30.0           12.0          10.0  2.150151\n",
       "6          30.0           18.0           3.0  2.355836\n",
       "7          30.0           18.0          10.0  2.373490"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we obtain the hyperparameters for the best combination by minimizing mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# first is to know which combination provides the minimized mae \n",
    "# use idxmin() function to check \n",
    "min_index = result['mae'].idxmin()\n",
    "# will return the index number \n",
    "print(min_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we obtain the numbers for the three hidden layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized number for the first layer is  30.0\n",
      "Optimized number for the second layer is  12.0\n",
      "Optimized number for the third layer is  10.0\n"
     ]
    }
   ],
   "source": [
    "first_hidden_best = result['first_hidden'][min_index]\n",
    "second_hidden_best = result['second_hidden'][min_index]\n",
    "third_hidden_best = result['third_hidden'][min_index]\n",
    "\n",
    "print(\"Optimized number for the first layer is \",first_hidden_best)\n",
    "print(\"Optimized number for the second layer is \",second_hidden_best)\n",
    "print(\"Optimized number for the third layer is \",third_hidden_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 22.8974 - val_loss: 22.5999\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 22.5691 - val_loss: 22.3543\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 22.3393 - val_loss: 22.1549\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 22.1206 - val_loss: 21.9173\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 21.8428 - val_loss: 21.5821\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 21.4313 - val_loss: 21.0610\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 20.7996 - val_loss: 20.2461\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 19.8181 - val_loss: 19.0575\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 18.4074 - val_loss: 17.4522\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 16.5996 - val_loss: 15.3057\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 14.2583 - val_loss: 12.6698\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 0s 74us/step - loss: 11.3830 - val_loss: 9.8955\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 8.6567 - val_loss: 8.1542\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 7.3555 - val_loss: 7.4517\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 6.9728 - val_loss: 6.8768\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 6.3594 - val_loss: 6.3332\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 5.7816 - val_loss: 5.8005\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 5.3447 - val_loss: 5.3782\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 5.0307 - val_loss: 5.0358\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 4.7283 - val_loss: 4.8600\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 4.5143 - val_loss: 4.5836\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 0s 80us/step - loss: 4.2767 - val_loss: 4.3476\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 0s 83us/step - loss: 4.0979 - val_loss: 4.1911\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 3.9869 - val_loss: 4.0398\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 3.8981 - val_loss: 3.9426\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.8209 - val_loss: 3.8617\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.7522 - val_loss: 3.7782\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.7188 - val_loss: 3.7037\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.6495 - val_loss: 3.6343\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.6117 - val_loss: 3.6048\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.5077 - val_loss: 3.5086\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.5080 - val_loss: 3.4277\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.4336 - val_loss: 3.3704\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.3988 - val_loss: 3.3011\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 3.3656 - val_loss: 3.2986\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 3.3019 - val_loss: 3.2027\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 3.3184 - val_loss: 3.1566\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 3.2215 - val_loss: 3.1987\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.2013 - val_loss: 3.1497\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 0s 52us/step - loss: 3.1510 - val_loss: 3.1004\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.1019 - val_loss: 2.9748\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 0s 59us/step - loss: 3.0709 - val_loss: 2.9542\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 3.0148 - val_loss: 2.9285\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 0s 56us/step - loss: 3.0161 - val_loss: 2.9429\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.9670 - val_loss: 2.8097\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 0s 65us/step - loss: 2.9003 - val_loss: 2.7914\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.8686 - val_loss: 2.7667\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.8482 - val_loss: 2.7042\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 0s 62us/step - loss: 2.7866 - val_loss: 2.7122\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 0s 77us/step - loss: 2.7680 - val_loss: 2.6352\n",
      "102/102 [==============================] - 0s 78us/step\n",
      "Mean absolute Error for the test set:  3.2563368269041475\n"
     ]
    }
   ],
   "source": [
    "# first, change the hidden_best from float back to integer\n",
    "first_hidden_best  = int(first_hidden_best)\n",
    "second_hidden_best = int(second_hidden_best)\n",
    "third_hidden_best  = int(third_hidden_best)\n",
    "\n",
    "# then train the model again\n",
    "min_model = boston_model(first_hidden_best,second_hidden_best,third_hidden_best)\n",
    "min_model.fit(x_train, y_train, epochs=50, validation_data=(x_valid, y_valid))\n",
    "min_mae = min_model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"Mean absolute Error for the test set: \", min_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
